{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Topic Modeling with gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "\n",
    "If not already installed, pip install `gensim` and `pyldavis` in your environment. \n",
    "\n",
    "Furthermore, we have to download some data for some specific NLTK modules. Download them by executing the following cell (you only have to do this once):\n",
    "\n",
    "Bird, S., Loper, E., & Klein, E. (2009). *Natural language processing with Python*. Sebastopol, CA: O'Reilly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rupertkiddle/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rupertkiddle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /Users/rupertkiddle/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rupertkiddle/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get started!\n",
    "\n",
    "## Import modules\n",
    "Before we start, let's import some modules that we need today. It is good practice to do so at the beginning of a script, so we'll do it right now and not later when we need them. \n",
    "\n",
    "The benefit is that you immediately see if something goes wrong (for instance, because the module is not installed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD LIBRARIES - \n",
    "import csv  # to read csv files\n",
    "import re  # for regular expressions\n",
    "from glob import glob  # to find files using patterns\n",
    "from string import punctuation  # to get punctuation\n",
    "import random  # for random number generation\n",
    "from datetime import datetime  # for datetimes\n",
    "\n",
    "#THID PARTY LIBRARIES -\n",
    "import nltk  # for POS tagging\n",
    "from nltk.sentiment import vader  # for sentiment analysis\n",
    "from nltk.corpus import stopwords  # for stopwords\n",
    "\n",
    "import gensim  # for LDA\n",
    "from gensim import corpora  # for LDA\n",
    "from gensim import models  # for LDA\n",
    "\n",
    "import pyLDAvis  # for LDA visualization\n",
    "import pyLDAvis.gensim_models as gensimvis  # for LDA visualization\n",
    "\n",
    "import pandas as pd  # for dataframes\n",
    "import seaborn as sns  # for visualization\n",
    "import matplotlib.pyplot as plt  # for visualization\n",
    "import numpy as np  # for numerical operations\n",
    "\n",
    "#INITIALIZATION -\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "#NOTE: If you set a random seed *and* pass `distributed=False` as an argument to your models, you get reproducable results.\n",
    "datadir = \"/Users/rupertkiddle/Desktop/teach/2024/Introduction to Machine Learning (GESIS)/3_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your gensim version is 4.3.3. This notebook assumes that you have version 4.0 or higher. If not, please upgrade.\n",
      "Your pyLDAvis version is 3.4.0. This notebook assumes that you have version 3.0 or higher. If not, please upgrade.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Your gensim version is {gensim.__version__}. This notebook assumes that you have version 4.0 or higher. If not, please upgrade.\")\n",
    "assert int(gensim.__version__[0])>=4\n",
    "\n",
    "print(f\"Your pyLDAvis version is {pyLDAvis.__version__}. This notebook assumes that you have version 3.0 or higher. If not, please upgrade.\")\n",
    "assert int(pyLDAvis.__version__[0])>=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "We will use a dataset by Schumacher et al. (2016). From the abstract:\n",
    "> This paper presents EUSpeech, a new dataset of 18,403 speeches from EU leaders (i.e., heads of government in 10 member states, EU commissioners, party leaders in the European Parliament, and ECB and IMF leaders) from 2007 to 2015. These speeches vary in sentiment, topics and ideology, allowing for fine-grained, over-time comparison of representation in the EU. The member states we included are Czech Republic, France, Germany, Greece, Netherlands, Italy, Spain, United Kingdom, Poland and Portugal.\n",
    "\n",
    "Schumacher, G, Schoonvelde, M., Dahiya, T., Traber, D, & de Vries, E. (2016): *EUSpeech: a New Dataset of EU Elite Speeches*. [doi:10.7910/DVN/XPCVEI](http://dx.doi.org/10.7910/DVN/XPCVEI)\n",
    "\n",
    "Download and unpack the following file:\n",
    "```\n",
    "speeches_csv.tar.gz\n",
    "```\n",
    "\n",
    "In the .tar.gz file, you find a .zip file. Extract the whole folder to your home directory.\n",
    "See below a screenshot of how this looks like in Lubuntu (double-click on \"speeches_csv.zip\" in the left window, then the right window will open. Click on \"Extract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"https://github.com/damian0604/bdaca/raw/master/ipynb/euspeech_download.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the files we downloaded.\n",
    "\n",
    "**NB: This command line magic only works on Linux and MacOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: /Users/rupertkiddle/Downloads/Cleaned_Speeches/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%ls ~/Downloads/Cleaned_Speeches/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start!\n",
    "Let's retrieve a list of all speeches from one of the files. Of course, we could also loop over all the files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/rupertkiddle/Desktop/teach/2024/Introduction to Machine Learning (GESIS)/3_datasets/Cleaned_Speeches/speeches_UK_Cleaned.csv']\n",
      "Number of speeches: 787\n"
     ]
    }
   ],
   "source": [
    "#filelist = glob('Cleaned_Speeches/Speeches_*_Cleaned.csv')\n",
    "\n",
    "# instead of all speeches, to speed things up, we are focusing on speeches from the Netherlands only\n",
    "filelist = glob(datadir+'/Cleaned_Speeches/speeches_UK_Cleaned.csv')\n",
    "print(filelist)\n",
    "speeches_eng=[]\n",
    "for fn in filelist:\n",
    "    with open(fn) as fi:\n",
    "        reader=csv.reader(fi)\n",
    "        for row in reader:\n",
    "            if row[7]=='en':   # only include english-language speches; we might as well choose 'nl' or 'fr'\n",
    "                speeches_eng.append(row[5])\n",
    "\n",
    "print(f\"Number of speeches: {len(speeches_eng)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed things up, we could also sample some speeches. \n",
    "# speeches = random.sample(speeches,100)\n",
    "# len(speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>This European Council has focused on 3 issues – the UK renegotiation, migration and terrorism.</p><p>I talked about the renegotiation last night and I will come back to it shortly – but first the other 2 issues.</p><p>Yesterday afternoon, we discu'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_eng[0][:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. From text to features: preprocessing, tokens, n-grams \n",
    "## General approach\n",
    "\n",
    "From a machine-learning perspective, one could argue that all information in a text might be useful information. However, we are interested in getting *interpretable* topics, so even if for instance the use of specific HTML tags would help us distinguising between some documents, we want to get rid of them. More in general, we start by cleaning up a bit to get only 'real' text.\n",
    "\n",
    "### Some typical clean-up steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_eng=[speech.replace('<p>',' ').replace('</p>',' ') for speech in speeches_eng]   #remove HTML tags\n",
    "speeches_eng=[\"\".join([l for l in speech if l not in punctuation]) for speech in speeches_eng]  #remove punctuation\n",
    "speeches_eng=[speech.lower() for speech in speeches_eng]  # convert to lower case\n",
    "speeches_eng=[\" \".join(speech.split()) for speech in speeches_eng]   # remove double spaces by splitting the strings into words and joining these words again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first speech to check everything's fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this european council has focused on 3 issues – the uk renegotiation migration and terrorism i talked about the renegotiation last night and i will come back to it shortly – but first the other 2 issues yesterday afternoon we discussed the ongoing migration crisis facing europe even with the onset of winter there are still many migrants coming to europe – with around 5000 arriving via the eastern mediterranean route each day britain has its own strict border controls which apply to everyone atte'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_eng[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as with other unsupervised machine learning techniques, we are not really interesting a long string of text. \n",
    "\n",
    "We rather want to have each document being represented by a set of *features*. \n",
    "\n",
    "To this end, `gensim` has a finciton `doc2bow` that converts a list of words (tokens) to `(token_id, token_count)` tuples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: to avoid messing things up, I'll call all objects relating to our first model _m1\n",
    "\n",
    "ldainput_m1 = [speech.split() for speech in speeches_eng]           # convert all strings to list of words\n",
    "id2word_m1 = corpora.Dictionary(ldainput_m1)                        # assign a token_id to each word\n",
    "ldacorpus_m1 = [id2word_m1.doc2bow(doc) for doc in ldainput_m1]     # represent each speech by (token_id, token_count) tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just run a simple LDA on this to check out whether it works. We specify the corpus (in wich each document is represented by a `(token_id, token_count)` tuple), the table to translate the token_id's back to words, and the number of topics we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.070*\"the\" + 0.035*\"and\" + 0.035*\"to\" + 0.027*\"of\" + 0.024*\"that\" + 0.022*\"in\" + 0.020*\"we\" + 0.019*\"a\" + 0.015*\"is\" + 0.011*\"are\"'),\n",
       " (1,\n",
       "  '0.043*\"the\" + 0.037*\"to\" + 0.032*\"that\" + 0.027*\"and\" + 0.023*\"of\" + 0.022*\"in\" + 0.018*\"we\" + 0.017*\"a\" + 0.015*\"is\" + 0.014*\"i\"'),\n",
       " (2,\n",
       "  '0.056*\"the\" + 0.040*\"and\" + 0.039*\"to\" + 0.025*\"of\" + 0.021*\"in\" + 0.021*\"that\" + 0.018*\"is\" + 0.017*\"a\" + 0.011*\"we\" + 0.011*\"i\"'),\n",
       " (3,\n",
       "  '0.045*\"the\" + 0.036*\"to\" + 0.032*\"and\" + 0.024*\"of\" + 0.020*\"that\" + 0.019*\"in\" + 0.018*\"a\" + 0.017*\"we\" + 0.015*\"i\" + 0.015*\"is\"'),\n",
       " (4,\n",
       "  '0.043*\"the\" + 0.038*\"to\" + 0.032*\"and\" + 0.029*\"of\" + 0.023*\"we\" + 0.022*\"that\" + 0.022*\"a\" + 0.019*\"is\" + 0.017*\"in\" + 0.016*\"i\"'),\n",
       " (5,\n",
       "  '0.057*\"the\" + 0.037*\"to\" + 0.031*\"and\" + 0.024*\"of\" + 0.022*\"that\" + 0.021*\"in\" + 0.017*\"a\" + 0.016*\"i\" + 0.014*\"we\" + 0.014*\"is\"'),\n",
       " (6,\n",
       "  '0.043*\"the\" + 0.031*\"to\" + 0.030*\"of\" + 0.030*\"that\" + 0.022*\"in\" + 0.022*\"and\" + 0.018*\"we\" + 0.016*\"is\" + 0.016*\"a\" + 0.014*\"i\"'),\n",
       " (7,\n",
       "  '0.051*\"the\" + 0.041*\"and\" + 0.032*\"to\" + 0.024*\"of\" + 0.021*\"in\" + 0.019*\"a\" + 0.018*\"i\" + 0.018*\"that\" + 0.015*\"we\" + 0.013*\"is\"'),\n",
       " (8,\n",
       "  '0.038*\"to\" + 0.037*\"the\" + 0.037*\"and\" + 0.021*\"of\" + 0.020*\"a\" + 0.019*\"that\" + 0.018*\"is\" + 0.017*\"i\" + 0.016*\"in\" + 0.014*\"have\"'),\n",
       " (9,\n",
       "  '0.040*\"and\" + 0.037*\"the\" + 0.029*\"to\" + 0.025*\"of\" + 0.025*\"in\" + 0.023*\"that\" + 0.020*\"is\" + 0.019*\"we\" + 0.014*\"a\" + 0.011*\"have\"')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_m1 = models.LdaModel(ldacorpus_m1, id2word=id2word_m1, num_topics=10)\n",
    "lda_m1.print_topics(num_words=5)\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "We immediately see that the result of our first LDA doesn't make much sense: We see only stopwords. \n",
    "\n",
    "\n",
    "### Explicit stopword removal\n",
    "The most straightforward approach is to use a pre-existing list with stopwords, possibly with the addition of some own, case-specific words. We then split up each speech in words, and only if a word is not on the stopwordlist, we keep it and join it with the previous and next word using a space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystopwords = set(stopwords.words('english')) # use default NLTK stopword list; alternatively:\n",
    "# mystopwords = set(open('mystopwordfile.txt').readlines())  #read stopword list from a textfile with one stopword per line\n",
    "\n",
    "speeches_eng_clean = [\" \".join([w for w in speech.split() if w not in mystopwords]) for speech in speeches_eng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'european council focused 3 issues – uk renegotiation migration terrorism talked renegotiation last night come back shortly – first 2 issues yesterday afternoon discussed ongoing migration crisis facing europe even onset winter still many migrants coming europe – around 5000 arriving via eastern mediterranean route day britain strict border controls apply everyone attempting enter united kingdom every day border controls helping keep us safe outside schengen ready help european partners secure bo'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_eng_clean[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether this looks better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"people\" + 0.010*\"think\" + 0.007*\"want\" + 0.006*\"make\" + 0.006*\"world\"'),\n",
       " (1,\n",
       "  '0.009*\"people\" + 0.008*\"think\" + 0.006*\"minister\" + 0.006*\"it’s\" + 0.006*\"–\"'),\n",
       " (2,\n",
       "  '0.011*\"people\" + 0.009*\"think\" + 0.009*\"–\" + 0.007*\"make\" + 0.006*\"got\"'),\n",
       " (3,\n",
       "  '0.012*\"people\" + 0.007*\"think\" + 0.007*\"world\" + 0.005*\"want\" + 0.005*\"country\"'),\n",
       " (4,\n",
       "  '0.009*\"think\" + 0.009*\"people\" + 0.008*\"world\" + 0.006*\"want\" + 0.006*\"–\"'),\n",
       " (5,\n",
       "  '0.012*\"people\" + 0.009*\"think\" + 0.008*\"–\" + 0.005*\"work\" + 0.005*\"world\"'),\n",
       " (6,\n",
       "  '0.012*\"people\" + 0.009*\"think\" + 0.007*\"minister\" + 0.006*\"want\" + 0.006*\"also\"'),\n",
       " (7,\n",
       "  '0.009*\"people\" + 0.006*\"country\" + 0.006*\"–\" + 0.006*\"think\" + 0.006*\"world\"'),\n",
       " (8,\n",
       "  '0.009*\"people\" + 0.006*\"think\" + 0.006*\"it’s\" + 0.006*\"prime\" + 0.006*\"world\"'),\n",
       " (9,\n",
       "  '0.011*\"think\" + 0.010*\"people\" + 0.006*\"one\" + 0.005*\"minister\" + 0.005*\"want\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldainput_m2 = [speech.split() for speech in speeches_eng_clean]      # speechesclean instead of speeches\n",
    "id2word_m2 = corpora.Dictionary(ldainput_m2)                       \n",
    "ldacorpus_m2 = [id2word_m2.doc2bow(doc) for doc in ldainput_m2]  \n",
    "lda_m2 = models.LdaModel(ldacorpus_m2, id2word=id2word_m2, num_topics=10)\n",
    "lda_m2.print_topics(num_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF scores instead of word counts as features\n",
    "Explicitly removing stopwords is a common practice and often very useful. We shouldn't forget, though, that there are some problematic aspects to it as well\n",
    "- It is kind of arbitrary what is on the stopword list and what not.\n",
    "- Depending on the research question one is interested in, it might differ what words are 'meaningful'.\n",
    "- Although the list is meant to consist of words that occur with a high frequency in all texts, it is not based on actual frequencies in the corpus but set a priori.\n",
    "\n",
    "A different (perhaps better) approach would therefore be to simply use (a) the frequency of each word in the corpus and (b) the number of documents in which the document occurs. \n",
    "\n",
    "In other words: If we use tf-idf scores (term frequency weighed by the inverse document frequncy) instead of raw word counts as featues, the stopwords should disappear automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"–\" + 0.000*\"iraq\" + 0.000*\"muslims\" + 0.000*\"bill\" + 0.000*\"you\"'),\n",
       " (1,\n",
       "  '0.001*\"–\" + 0.001*\"pakistan\" + 0.001*\"afghanistan\" + 0.001*\"afghan\" + 0.000*\"eu\"'),\n",
       " (2,\n",
       "  '0.001*\"–\" + 0.000*\"you\" + 0.000*\"afghanistan\" + 0.000*\"global\" + 0.000*\"israel\"'),\n",
       " (3, '0.001*\"–\" + 0.000*\"you\" + 0.000*\"think\" + 0.000*\"trade\" + 0.000*\"got\"'),\n",
       " (4, '0.001*\"–\" + 0.001*\"you\" + 0.001*\"think\" + 0.001*\"it’s\" + 0.000*\"we’ve\"'),\n",
       " (5, '0.001*\"–\" + 0.000*\"it’s\" + 0.000*\"think\" + 0.000*\"you\" + 0.000*\"nhs\"'),\n",
       " (6,\n",
       "  '0.001*\"–\" + 0.001*\"afghanistan\" + 0.001*\"it’s\" + 0.001*\"you\" + 0.001*\"think\"'),\n",
       " (7,\n",
       "  '0.001*\"–\" + 0.001*\"carbon\" + 0.000*\"it’s\" + 0.000*\"european\" + 0.000*\"we’re\"'),\n",
       " (8, '0.001*\"–\" + 0.000*\"you\" + 0.000*\"think\" + 0.000*\"nhs\" + 0.000*\"it’s\"'),\n",
       " (9,\n",
       "  '0.001*\"–\" + 0.000*\"it’s\" + 0.000*\"think\" + 0.000*\"you\" + 0.000*\"business\"')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldacorpus_m3 = ldacorpus_m1     # reuse corpus from Model 1 \n",
    "id2word_m3 = id2word_m1          # and thus, also use id2word-mapping\n",
    "tfidfcorpus_m3 = models.TfidfModel(ldacorpus_m3) # create a TF-IDF model from the corpus\n",
    "lda_m3 = models.ldamodel.LdaModel(corpus=tfidfcorpus_m3[ldacorpus_m3],id2word=id2word_m3,num_topics=10) # train LDA model\n",
    "lda_m3.print_topics(num_words=5) # print topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering extremes\n",
    "Just as we don't want to include words that are all over the place and do little to distinguish documents, we also do not want to include words that virtually never occur. If among millions of words, a word occurs exactly one time, it might be simply a spelling mistake. But even if it is not, it does not help us to infer topics across documents. \n",
    "\n",
    "Also in purely pragmatic terms, it makes sense to remove unneccessary features to speed up the analysis process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"–\" + 0.001*\"palestinian\" + 0.001*\"ireland\" + 0.001*\"european\" + 0.001*\"nhs\"'),\n",
       " (1,\n",
       "  '0.002*\"–\" + 0.001*\"iraq\" + 0.001*\"syria\" + 0.001*\"eu\" + 0.001*\"speaker\"'),\n",
       " (2,\n",
       "  '0.001*\"–\" + 0.001*\"afghanistan\" + 0.001*\"european\" + 0.001*\"relationship\" + 0.001*\"speaker\"'),\n",
       " (3,\n",
       "  '0.002*\"–\" + 0.001*\"afghanistan\" + 0.001*\"we’re\" + 0.001*\"afghan\" + 0.001*\"oil\"'),\n",
       " (4,\n",
       "  '0.002*\"–\" + 0.001*\"european\" + 0.001*\"we’re\" + 0.001*\"global\" + 0.001*\"union\"'),\n",
       " (5,\n",
       "  '0.003*\"–\" + 0.001*\"nhs\" + 0.001*\"afghanistan\" + 0.001*\"care\" + 0.001*\"ireland\"'),\n",
       " (6,\n",
       "  '0.002*\"afghanistan\" + 0.001*\"pakistan\" + 0.001*\"–\" + 0.001*\"afghan\" + 0.001*\"nhs\"'),\n",
       " (7,\n",
       "  '0.002*\"–\" + 0.001*\"bill\" + 0.001*\"wales\" + 0.001*\"ireland\" + 0.001*\"social\"'),\n",
       " (8,\n",
       "  '0.002*\"–\" + 0.001*\"global\" + 0.001*\"iran\" + 0.001*\"question\" + 0.001*\"we’re\"'),\n",
       " (9,\n",
       "  '0.002*\"–\" + 0.001*\"global\" + 0.001*\"european\" + 0.001*\"afghanistan\" + 0.001*\"trade\"')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word_m4 = corpora.Dictionary(ldainput_m1)           # reuse input from M1     \n",
    "\n",
    "id2word_m4.filter_extremes(no_below=5, no_above=0.5)   # do not consider all words that occur in less than n=5 documents\n",
    "                                                       # or in more than 50% of all documents.\n",
    "\n",
    "ldacorpus_m4 = [id2word_m4.doc2bow(doc) for doc in ldainput_m1]\n",
    "tfidfcorpus_m4 = models.TfidfModel(ldacorpus_m4)\n",
    "lda_m4 = models.ldamodel.LdaModel(corpus=tfidfcorpus_m4[ldacorpus_m4],id2word=id2word_m4,num_topics=10, distributed=False, random_state=42) \n",
    "lda_m4.print_topics(num_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other preprocessing ideas\n",
    "\n",
    "### Stemming\n",
    "Stemming can be useful to avoid that 'economics', 'economic', and 'economy' are seen as different concepts by the topic model. In practice, however, standard stemming algorithms are far from perfect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this european council has focus on 3 issu – the uk renegoti migrat and terror i talk about the renegoti last night and i will come back to it short – but first the other 2 issu yesterday afternoon we discuss the ongo migrat crisi face europ even with the onset of winter there are still mani migrant come to europ – with around 5000 arriv via the eastern mediterranean rout each day britain has it own strict border control which appli to everyon attempt to enter the unit kingdom and everi day those'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.snowball.EnglishStemmer()\n",
    "speeches_eng_stemmed = [\" \".join([stemmer.stem(word) for word in speech.split()]) for speech in speeches_eng]\n",
    "speeches_eng_stemmed[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing and retaining only nouns and adjectives\n",
    "Depending on the specific use case at hand, one might discover that some parts of speech (POS) are more informative than others. We could, for instance, create a topic model based on only the nouns and adjectives in a text, disregarding everything else. \n",
    "Look at the NLTK documentation to find out what each code means (e.g., 'NN' is 'noun') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_eng_nounsadj=[]\n",
    "for speech in speeches_eng:\n",
    "    tokens = nltk.word_tokenize(speech)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    cleanspeech = \"\"\n",
    "    for element in tagged:\n",
    "        if element[1] in ('NN','NNP','JJ'):\n",
    "            cleanspeech=cleanspeech+element[0]+\" \"\n",
    "    speeches_eng_nounsadj.append(cleanspeech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'european council uk renegotiation migration terrorism i renegotiation last night i other yesterday afternoon ongoing migration crisis onset winter many – eastern mediterranean route day britain own strict border everyone united kingdom day border safe outside schengen ready european start united kingdom comprehensive approach root migration crisis – vast europe ’ £12 humanitarian assistance syrian conflict hms enterprise police mediterranean ’ practical assistance registering fingerprinting gree'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_eng_nounsadj[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using ngrams as features\n",
    "Topic models follow a bag-of-words approach, meaning they do not take word order into account. However, sometimes we want to be able to do so to a limited extend: The \"white house\" is something else than a \"house with a white wall\", even though both strings contain the words 'white' and 'house'. We can do so by joining adjacent words together in so-called bigrams (or trigrams, if we take three words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_eng_bigrams = [[\"_\".join(tup) for tup in nltk.ngrams(speech.split(),2)] for speech in speeches_eng_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['police_officers',\n",
       " 'officers_mediterranean',\n",
       " 'mediterranean_go',\n",
       " 'go_traffickers',\n",
       " 'traffickers_it’s',\n",
       " 'it’s_offered',\n",
       " 'offered_practical',\n",
       " 'practical_assistance',\n",
       " 'assistance_help',\n",
       " 'help_registering',\n",
       " 'registering_fingerprinting',\n",
       " 'fingerprinting_migrants',\n",
       " 'migrants_countries',\n",
       " 'countries_land',\n",
       " 'land_like',\n",
       " 'like_greece',\n",
       " 'greece_italy',\n",
       " 'italy_indeed',\n",
       " 'indeed_provided',\n",
       " 'provided_technical',\n",
       " 'technical_expertise',\n",
       " 'expertise_european',\n",
       " 'european_asylum',\n",
       " 'asylum_support',\n",
       " 'support_office',\n",
       " 'office_country',\n",
       " 'country_summit',\n",
       " 'summit_discussed',\n",
       " 'discussed_importance',\n",
       " 'importance_implementing',\n",
       " 'implementing_measures',\n",
       " 'measures_previously',\n",
       " 'previously_agreed',\n",
       " 'agreed_back',\n",
       " 'back_summer',\n",
       " 'summer_frank',\n",
       " 'frank_discussions',\n",
       " 'discussions_countries',\n",
       " 'countries_committed',\n",
       " 'committed_resettle',\n",
       " 'resettle_22000',\n",
       " '22000_refugees',\n",
       " 'refugees_syria',\n",
       " 'syria_2',\n",
       " '2_years',\n",
       " 'years_relocate',\n",
       " 'relocate_160000',\n",
       " '160000_migrants',\n",
       " 'migrants_arriving',\n",
       " 'arriving_‘hotspots’',\n",
       " '‘hotspots’_participating',\n",
       " 'participating_countries',\n",
       " 'countries_it’s',\n",
       " 'it’s_clear',\n",
       " 'clear_others',\n",
       " 'others_said',\n",
       " 'said_relocated',\n",
       " 'relocated_settled',\n",
       " 'settled_alongside',\n",
       " 'alongside_announced',\n",
       " 'announced_united',\n",
       " 'united_kingdom',\n",
       " 'kingdom_would',\n",
       " 'would_resettle',\n",
       " 'resettle_20000',\n",
       " '20000_syrian',\n",
       " 'syrian_refugees',\n",
       " 'refugees_parliament',\n",
       " 'parliament_meeting',\n",
       " 'meeting_ambition',\n",
       " 'ambition_set',\n",
       " 'set_since',\n",
       " 'since_september',\n",
       " 'september_resettled',\n",
       " 'resettled_1000',\n",
       " '1000_syrian',\n",
       " 'syrian_refugees',\n",
       " 'refugees_camps',\n",
       " 'camps_turkey',\n",
       " 'turkey_jordan',\n",
       " 'jordan_lebanon',\n",
       " 'lebanon_homes',\n",
       " 'homes_children',\n",
       " 'children_schools',\n",
       " 'schools_look',\n",
       " 'look_forward',\n",
       " 'forward_new',\n",
       " 'new_year',\n",
       " 'year_free',\n",
       " 'free_fear',\n",
       " 'fear_uncertainty',\n",
       " 'uncertainty_prospect',\n",
       " 'prospect_building',\n",
       " 'building_new',\n",
       " 'new_life',\n",
       " 'life_britain',\n",
       " 'britain_united',\n",
       " 'united_kingdom',\n",
       " 'kingdom_continue',\n",
       " 'continue_play',\n",
       " 'play_full',\n",
       " 'full_part',\n",
       " 'part_helping',\n",
       " 'helping_affected',\n",
       " 'affected_syrian',\n",
       " 'syrian_crisis',\n",
       " 'crisis_conference',\n",
       " 'conference_cohost',\n",
       " 'cohost_germany',\n",
       " 'germany_kuwait',\n",
       " 'kuwait_norway',\n",
       " 'norway_un',\n",
       " 'un_next',\n",
       " 'next_february',\n",
       " 'february_turning',\n",
       " 'turning_terrorism',\n",
       " 'terrorism_horrific',\n",
       " 'horrific_attacks',\n",
       " 'attacks_paris',\n",
       " 'paris_last',\n",
       " 'last_month',\n",
       " 'month_underline',\n",
       " 'underline_threat',\n",
       " 'threat_face',\n",
       " 'face_daesh',\n",
       " 'daesh_happened',\n",
       " 'happened_friday',\n",
       " 'friday_night',\n",
       " 'night_last',\n",
       " 'last_month',\n",
       " 'month_paris',\n",
       " 'paris_could',\n",
       " 'could_happened',\n",
       " 'happened_european',\n",
       " 'european_city',\n",
       " 'city_face',\n",
       " 'face_common',\n",
       " 'common_threat',\n",
       " 'threat_one',\n",
       " 'one_country',\n",
       " 'country_defeat',\n",
       " 'defeat_alone',\n",
       " 'alone_defeat',\n",
       " 'defeat_together',\n",
       " 'together_made',\n",
       " 'made_important',\n",
       " 'important_progress',\n",
       " 'progress_last',\n",
       " 'last_week',\n",
       " 'week_provisional',\n",
       " 'provisional_agreement',\n",
       " 'agreement_council',\n",
       " 'council_european',\n",
       " 'european_parliament',\n",
       " 'parliament_new',\n",
       " 'new_rules',\n",
       " 'rules_share',\n",
       " 'share_passenger',\n",
       " 'passenger_name',\n",
       " 'name_records',\n",
       " 'records_absolutely',\n",
       " 'absolutely_vital',\n",
       " 'vital_piece',\n",
       " 'piece_work',\n",
       " 'work_must',\n",
       " 'must_need',\n",
       " 'need_systematic',\n",
       " 'systematic_data',\n",
       " 'data_sharing',\n",
       " 'sharing_track',\n",
       " 'track_stop',\n",
       " 'stop_terrorists',\n",
       " 'terrorists_must',\n",
       " 'must_step',\n",
       " 'step_cooperation',\n",
       " 'cooperation_aviation',\n",
       " 'aviation_security',\n",
       " 'security_need',\n",
       " 'need_go',\n",
       " 'go_daesh’s',\n",
       " 'daesh’s_finances',\n",
       " 'finances_choking',\n",
       " 'choking_oil',\n",
       " 'oil_money',\n",
       " 'money_counter',\n",
       " 'counter_extremists’',\n",
       " 'extremists’_propaganda',\n",
       " 'propaganda_poisonous',\n",
       " 'poisonous_narrative',\n",
       " 'narrative_must',\n",
       " 'must_clamp',\n",
       " 'clamp_firearms',\n",
       " 'firearms_explosives',\n",
       " 'explosives_–',\n",
       " '–_stopping',\n",
       " 'stopping_getting',\n",
       " 'getting_hands',\n",
       " 'hands_evil',\n",
       " 'evil_terrorists',\n",
       " 'terrorists_determined',\n",
       " 'determined_wreak',\n",
       " 'wreak_misery',\n",
       " 'misery_pleased',\n",
       " 'pleased_got',\n",
       " 'got_clear',\n",
       " 'clear_agreement',\n",
       " 'agreement_rapidly',\n",
       " 'rapidly_take',\n",
       " 'take_forward',\n",
       " 'forward_proposals',\n",
       " 'proposals_areas',\n",
       " 'areas_requires',\n",
       " 'requires_closer',\n",
       " 'closer_cooperation',\n",
       " 'cooperation_right',\n",
       " 'right_common',\n",
       " 'common_challenge',\n",
       " 'challenge_migration',\n",
       " 'migration_threat',\n",
       " 'threat_terrorism',\n",
       " 'terrorism_instability',\n",
       " 'instability_libya',\n",
       " 'libya_syria',\n",
       " 'syria_that’s',\n",
       " 'that’s_it’s',\n",
       " 'it’s_important',\n",
       " 'important_work',\n",
       " 'work_together',\n",
       " 'together_support',\n",
       " 'support_strong',\n",
       " 'strong_stable',\n",
       " 'stable_inclusive',\n",
       " 'inclusive_governance',\n",
       " 'governance_countries',\n",
       " 'countries_today',\n",
       " 'today_reiterated',\n",
       " 'reiterated_eu’s',\n",
       " 'eu’s_support',\n",
       " 'support_efforts',\n",
       " 'efforts_international',\n",
       " 'international_syria',\n",
       " 'syria_support',\n",
       " 'support_group',\n",
       " 'group_end',\n",
       " 'end_conflict',\n",
       " 'conflict_syria',\n",
       " 'syria_political',\n",
       " 'political_process',\n",
       " 'process_welcome',\n",
       " 'welcome_agreement',\n",
       " 'agreement_reached',\n",
       " 'reached_morocco',\n",
       " 'morocco_yesterday',\n",
       " 'yesterday_hope',\n",
       " 'hope_pave',\n",
       " 'pave_way',\n",
       " 'way_new',\n",
       " 'new_united',\n",
       " 'united_national',\n",
       " 'national_government',\n",
       " 'government_libya',\n",
       " 'libya_unstable',\n",
       " 'unstable_world',\n",
       " 'world_britain',\n",
       " 'britain_playing',\n",
       " 'playing_leading',\n",
       " 'leading_role',\n",
       " 'role_eu',\n",
       " 'eu_issues',\n",
       " 'issues_security',\n",
       " 'security_–',\n",
       " '–_working',\n",
       " 'working_member',\n",
       " 'member_states',\n",
       " 'states_better',\n",
       " 'better_protect',\n",
       " 'protect_people',\n",
       " 'people_underlines',\n",
       " 'underlines_renegotiation',\n",
       " 'renegotiation_important',\n",
       " 'important_said',\n",
       " 'said_last',\n",
       " 'last_night',\n",
       " 'night_made',\n",
       " 'made_good',\n",
       " 'good_progress',\n",
       " 'progress_step',\n",
       " 'step_closer',\n",
       " 'closer_agreement',\n",
       " 'agreement_significant',\n",
       " 'significant_farreaching',\n",
       " 'farreaching_reforms',\n",
       " 'reforms_proposed',\n",
       " 'proposed_going',\n",
       " 'going_tough',\n",
       " 'tough_lots',\n",
       " 'lots_hard',\n",
       " 'hard_work',\n",
       " 'work_believe',\n",
       " 'believe_2016',\n",
       " '2016_year',\n",
       " 'year_achieve',\n",
       " 'achieve_something',\n",
       " 'something_really',\n",
       " 'really_vital',\n",
       " 'vital_fundamentally',\n",
       " 'fundamentally_changing',\n",
       " 'changing_uk’s',\n",
       " 'uk’s_relationship',\n",
       " 'relationship_eu',\n",
       " 'eu_finally',\n",
       " 'finally_addressing',\n",
       " 'addressing_concerns',\n",
       " 'concerns_british',\n",
       " 'british_people',\n",
       " 'people_membership',\n",
       " 'membership_british',\n",
       " 'british_people',\n",
       " 'people_decide',\n",
       " 'decide_whether',\n",
       " 'whether_remain',\n",
       " 'remain_leave',\n",
       " 'leave_choice',\n",
       " 'choice_need',\n",
       " 'need_think',\n",
       " 'think_hard',\n",
       " 'hard_believe',\n",
       " 'believe_get',\n",
       " 'get_reforms',\n",
       " 'reforms_right',\n",
       " 'right_–',\n",
       " '–_believe',\n",
       " 'believe_firmly',\n",
       " 'firmly_believe',\n",
       " 'believe_economic',\n",
       " 'economic_security',\n",
       " 'security_increasing',\n",
       " 'increasing_national',\n",
       " 'national_security',\n",
       " 'security_best',\n",
       " 'best_future',\n",
       " 'future_britain',\n",
       " 'britain_reformed',\n",
       " 'reformed_european',\n",
       " 'european_union',\n",
       " 'union_happy',\n",
       " 'happy_take',\n",
       " 'take_questions',\n",
       " 'questions_let’s',\n",
       " 'let’s_start',\n",
       " 'start_bbc',\n",
       " 'bbc_prime',\n",
       " 'prime_minister',\n",
       " 'minister_thank',\n",
       " 'thank_laura',\n",
       " 'laura_kuenssberg',\n",
       " 'kuenssberg_bbc',\n",
       " 'bbc_news',\n",
       " 'news_you’ve',\n",
       " 'you’ve_given',\n",
       " 'given_clear',\n",
       " 'clear_hint',\n",
       " 'hint_vote',\n",
       " 'vote_membership',\n",
       " 'membership_european',\n",
       " 'european_union',\n",
       " 'union_2016',\n",
       " '2016_previous',\n",
       " 'previous_major',\n",
       " 'major_changes',\n",
       " 'changes_european',\n",
       " 'european_union',\n",
       " 'union_taken',\n",
       " 'taken_long',\n",
       " 'long_time',\n",
       " 'time_amsterdam',\n",
       " 'amsterdam_treaty',\n",
       " 'treaty_took',\n",
       " 'took_2',\n",
       " '2_years',\n",
       " 'years_maastricht',\n",
       " 'maastricht_treaty',\n",
       " 'treaty_took',\n",
       " 'took_2',\n",
       " '2_years',\n",
       " 'years_confident',\n",
       " 'confident_changes',\n",
       " 'changes_want',\n",
       " 'want_–',\n",
       " '–_big',\n",
       " 'big_deal',\n",
       " 'deal_–',\n",
       " '–_done',\n",
       " 'done_2',\n",
       " '2_months',\n",
       " 'months_may',\n",
       " 'may_libya',\n",
       " 'libya_uk',\n",
       " 'uk_troops',\n",
       " 'troops_going',\n",
       " 'going_intervening',\n",
       " 'intervening_okay',\n",
       " 'okay_first',\n",
       " 'first_terms',\n",
       " 'terms_changes',\n",
       " 'changes_i’ve',\n",
       " 'i’ve_working',\n",
       " 'working_clear',\n",
       " 'clear_mandate',\n",
       " 'mandate_british',\n",
       " 'british_people',\n",
       " 'people_ever',\n",
       " 'ever_since',\n",
       " 'since_election',\n",
       " 'election_back',\n",
       " 'back_may',\n",
       " 'may_lot',\n",
       " 'lot_work',\n",
       " 'work_done',\n",
       " 'done_matters',\n",
       " 'matters_changes',\n",
       " 'changes_legally',\n",
       " 'legally_binding',\n",
       " 'binding_irreversible',\n",
       " 'irreversible_believe',\n",
       " 'believe_find',\n",
       " 'find_ways',\n",
       " 'ways_setting',\n",
       " 'setting_demonstrating',\n",
       " 'demonstrating_coming',\n",
       " 'coming_months',\n",
       " 'months_obviously',\n",
       " 'obviously_want',\n",
       " 'want_deal',\n",
       " 'deal_february',\n",
       " 'february_i’ve',\n",
       " 'i’ve_set',\n",
       " 'set_deadline',\n",
       " 'deadline_referendum',\n",
       " 'referendum_end',\n",
       " 'end_2017',\n",
       " '2017_always',\n",
       " 'always_wanted',\n",
       " 'wanted_give',\n",
       " 'give_time',\n",
       " 'time_get',\n",
       " 'get_right',\n",
       " 'right_matters',\n",
       " 'matters_substance',\n",
       " 'substance_–',\n",
       " '–_getting',\n",
       " 'getting_right',\n",
       " 'right_rather',\n",
       " 'rather_timing',\n",
       " 'timing_that’s',\n",
       " 'that’s_first',\n",
       " 'first_point',\n",
       " 'point_libya',\n",
       " 'libya_happened',\n",
       " 'happened_good',\n",
       " 'good_step',\n",
       " 'step_forward',\n",
       " 'forward_it’s',\n",
       " 'it’s_perfect',\n",
       " 'perfect_everyone',\n",
       " 'everyone_involved',\n",
       " 'involved_libyan',\n",
       " 'libyan_political',\n",
       " 'political_discussions',\n",
       " 'discussions_joined',\n",
       " 'joined_new',\n",
       " 'new_government',\n",
       " 'government_we’ve',\n",
       " 'we’ve_always',\n",
       " 'always_said',\n",
       " 'said_stand',\n",
       " 'stand_ready',\n",
       " 'ready_support',\n",
       " 'support_resources',\n",
       " 'resources_training',\n",
       " 'training_advice',\n",
       " 'advice_capacity',\n",
       " 'capacity_building',\n",
       " 'building_frankly',\n",
       " 'frankly_last',\n",
       " 'last_thing',\n",
       " 'thing_new',\n",
       " 'new_libyan',\n",
       " 'libyan_government',\n",
       " 'government_wants',\n",
       " 'wants_lot',\n",
       " 'lot_foreign',\n",
       " 'foreign_troops',\n",
       " 'troops_soil',\n",
       " 'soil_we’re',\n",
       " 'we’re_proposing',\n",
       " 'proposing_it’s',\n",
       " 'it’s_helping',\n",
       " 'helping_build',\n",
       " 'build_capacity',\n",
       " 'capacity_government',\n",
       " 'government_run',\n",
       " 'run_country',\n",
       " 'country_direct',\n",
       " 'direct_impact',\n",
       " 'impact_us',\n",
       " 'us_back',\n",
       " 'back_home',\n",
       " 'home_2',\n",
       " '2_reasons',\n",
       " 'reasons_one',\n",
       " 'one_libya',\n",
       " 'libya_become',\n",
       " 'become_broken',\n",
       " 'broken_state',\n",
       " 'state_criminal',\n",
       " 'criminal_gangs',\n",
       " 'gangs_able',\n",
       " 'able_use',\n",
       " 'use_jumping',\n",
       " 'jumping_point',\n",
       " 'point_migrant',\n",
       " 'migrant_boats',\n",
       " 'boats_across',\n",
       " 'across_med',\n",
       " 'med_weren’t',\n",
       " 'weren’t_proper',\n",
       " 'proper_authorities',\n",
       " 'authorities_us',\n",
       " 'us_work',\n",
       " 'work_libya',\n",
       " 'libya_put',\n",
       " 'put_stop',\n",
       " 'stop_government',\n",
       " 'government_libya',\n",
       " 'libya_absolutely',\n",
       " 'absolutely_crucial',\n",
       " 'crucial_able',\n",
       " 'able_deliver',\n",
       " 'deliver_end',\n",
       " 'end_migration',\n",
       " 'migration_route',\n",
       " 'route_secondly',\n",
       " 'secondly_many',\n",
       " 'many_ways',\n",
       " 'ways_even',\n",
       " 'even_significantly',\n",
       " 'significantly_presence',\n",
       " 'presence_daesh',\n",
       " 'daesh_libya',\n",
       " 'libya_need',\n",
       " 'need_government',\n",
       " 'government_partner',\n",
       " 'partner_work',\n",
       " 'work_us',\n",
       " 'us_–',\n",
       " '–_work',\n",
       " 'work_–',\n",
       " '–_right',\n",
       " 'right_thing',\n",
       " 'thing_country',\n",
       " 'country_make',\n",
       " 'make_sure',\n",
       " 'sure_daesh',\n",
       " 'daesh_cannot',\n",
       " 'cannot_foothold',\n",
       " 'foothold_country',\n",
       " 'country_it’s',\n",
       " 'it’s_early',\n",
       " 'early_days',\n",
       " 'days_agreement',\n",
       " 'agreement_signed',\n",
       " 'signed_rather',\n",
       " 'rather_government',\n",
       " 'government_actually',\n",
       " 'actually_place',\n",
       " 'place_everything',\n",
       " 'everything_back',\n",
       " 'back_support',\n",
       " 'support_itv',\n",
       " 'itv_prime',\n",
       " 'prime_minister',\n",
       " 'minister_reports',\n",
       " 'reports_morning',\n",
       " 'morning_you’re',\n",
       " 'you’re_offered',\n",
       " 'offered_emergency',\n",
       " 'emergency_break',\n",
       " 'break_inwork',\n",
       " 'inwork_benefits',\n",
       " 'benefits_eu',\n",
       " 'eu_migrants',\n",
       " 'migrants_brussels',\n",
       " 'brussels_agrees',\n",
       " 'agrees_public',\n",
       " 'public_services',\n",
       " 'services_risk',\n",
       " 'risk_–',\n",
       " '–_overwhelmed',\n",
       " 'overwhelmed_would',\n",
       " 'would_remotely',\n",
       " 'remotely_enough',\n",
       " 'enough_well',\n",
       " 'well_i’ve',\n",
       " 'i’ve_said',\n",
       " 'said_look',\n",
       " 'look_proposal',\n",
       " 'proposal_–',\n",
       " '–_4year',\n",
       " '4year_proposal',\n",
       " 'proposal_remains',\n",
       " 'remains_table',\n",
       " 'table_happened',\n",
       " 'happened_last',\n",
       " 'last_night',\n",
       " 'night_european',\n",
       " 'european_commission',\n",
       " 'commission_said',\n",
       " 'said_looking',\n",
       " 'looking_solutions',\n",
       " 'solutions_compromises',\n",
       " 'compromises_negotiation',\n",
       " 'negotiation_i’m',\n",
       " 'i’m_convinced',\n",
       " 'convinced_work',\n",
       " 'work_hard',\n",
       " 'hard_february',\n",
       " 'february_we’ll',\n",
       " 'we’ll_find',\n",
       " 'find_good',\n",
       " 'good_answer',\n",
       " 'answer_george',\n",
       " 'george_george',\n",
       " 'george_parker',\n",
       " 'parker_financial',\n",
       " 'financial_times',\n",
       " 'times_ask',\n",
       " 'ask_another',\n",
       " 'another_question',\n",
       " 'question_specific',\n",
       " 'specific_renegotiation',\n",
       " 'renegotiation_–',\n",
       " '–_idea',\n",
       " 'idea_redesignating',\n",
       " 'redesignating_eu',\n",
       " 'eu_multicurrency',\n",
       " 'multicurrency_union',\n",
       " 'union_running',\n",
       " 'running_resistance',\n",
       " 'resistance_hear',\n",
       " 'hear_president',\n",
       " 'president_european',\n",
       " 'european_central',\n",
       " 'central_bank',\n",
       " 'bank_concerned',\n",
       " 'concerned_make',\n",
       " 'make_explicit',\n",
       " 'explicit_countries',\n",
       " 'countries_example',\n",
       " 'example_poland',\n",
       " 'poland_might',\n",
       " 'might_see',\n",
       " 'see_–',\n",
       " '–_decide',\n",
       " 'decide_longer',\n",
       " 'longer_join',\n",
       " 'join_euro',\n",
       " 'euro_well',\n",
       " 'well_lot',\n",
       " 'lot_discussion',\n",
       " 'discussion_last',\n",
       " 'last_night',\n",
       " 'night_think',\n",
       " 'think_recognition',\n",
       " 'recognition_it’s',\n",
       " 'it’s_statement',\n",
       " 'statement_fact',\n",
       " 'fact_eu',\n",
       " 'eu_many',\n",
       " 'many_currencies',\n",
       " 'currencies_within',\n",
       " 'within_obviously',\n",
       " 'obviously_it’s',\n",
       " 'it’s_important',\n",
       " 'important_say',\n",
       " 'say_go',\n",
       " 'go_one',\n",
       " 'one_step',\n",
       " 'step_make',\n",
       " 'make_sure',\n",
       " 'sure_you’re',\n",
       " 'you’re_disadvantaged',\n",
       " 'disadvantaged_single',\n",
       " 'single_market',\n",
       " 'market_you’re',\n",
       " 'you’re_outside',\n",
       " 'outside_single',\n",
       " 'single_currency',\n",
       " 'currency_think',\n",
       " 'think_good',\n",
       " 'good_discussion',\n",
       " 'discussion_last',\n",
       " 'last_night',\n",
       " 'night_course',\n",
       " 'course_countries',\n",
       " 'countries_eurozone',\n",
       " 'eurozone_want',\n",
       " 'want_know',\n",
       " 'know_press',\n",
       " 'press_ahead',\n",
       " 'ahead_vital',\n",
       " 'vital_integration',\n",
       " 'integration_might',\n",
       " 'might_need',\n",
       " 'need_without',\n",
       " 'without_us',\n",
       " 'us_outside',\n",
       " 'outside_eurozone',\n",
       " 'eurozone_stopping',\n",
       " 'stopping_i’ve',\n",
       " 'i’ve_said',\n",
       " 'said_look',\n",
       " 'look_whole',\n",
       " 'whole_point',\n",
       " 'point_don’t',\n",
       " 'don’t_want',\n",
       " 'want_stand',\n",
       " 'stand_way',\n",
       " 'way_things',\n",
       " 'things_eurozone',\n",
       " 'eurozone_needs',\n",
       " 'needs_make',\n",
       " 'make_currency',\n",
       " 'currency_work',\n",
       " 'work_well',\n",
       " 'well_it’s',\n",
       " 'it’s_interests',\n",
       " 'interests_work',\n",
       " 'work_well',\n",
       " 'well_likewise',\n",
       " 'likewise_it’s',\n",
       " 'it’s_important',\n",
       " 'important_set',\n",
       " 'set_principles',\n",
       " 'principles_britain',\n",
       " 'britain_countries',\n",
       " 'countries_outside',\n",
       " 'outside_euro',\n",
       " 'euro_can’t',\n",
       " 'can’t_put',\n",
       " 'put_disadvantage',\n",
       " 'disadvantage_know',\n",
       " 'know_heart',\n",
       " 'heart_issue',\n",
       " 'issue_liable',\n",
       " 'liable_way',\n",
       " 'way_taxpayers’',\n",
       " 'taxpayers’_money',\n",
       " 'money_spent',\n",
       " 'spent_eurozonerelated',\n",
       " 'eurozonerelated_issues',\n",
       " 'issues_risk',\n",
       " 'risk_summer',\n",
       " 'summer_know',\n",
       " 'know_european',\n",
       " 'european_stability',\n",
       " 'stability_–',\n",
       " '–_financial',\n",
       " 'financial_stability',\n",
       " 'stability_mechanism',\n",
       " 'mechanism_used',\n",
       " 'used_bail',\n",
       " 'bail_greece',\n",
       " 'greece_stopped',\n",
       " 'stopped_happening',\n",
       " 'happening_shouldn’t',\n",
       " 'shouldn’t_know',\n",
       " 'know_make',\n",
       " 'make_ad',\n",
       " 'ad_hoc',\n",
       " 'hoc_efforts',\n",
       " 'efforts_stop',\n",
       " 'stop_happening',\n",
       " 'happening_written',\n",
       " 'written_clearly',\n",
       " 'clearly_principles',\n",
       " 'principles_disadvantage',\n",
       " 'disadvantage_discrimination',\n",
       " 'discrimination_eurozone',\n",
       " 'eurozone_countries',\n",
       " 'countries_pay',\n",
       " 'pay_eurozone',\n",
       " 'eurozone_issues',\n",
       " 'issues_it’s',\n",
       " 'it’s_–',\n",
       " '–_know',\n",
       " 'know_said',\n",
       " 'said_last',\n",
       " 'last_night',\n",
       " 'night_none',\n",
       " 'none_4',\n",
       " '4_issues',\n",
       " 'issues_easy',\n",
       " 'easy_deliver',\n",
       " 'deliver_it’s',\n",
       " 'it’s_mistake',\n",
       " 'mistake_think',\n",
       " 'think_you’ve',\n",
       " 'you’ve_got',\n",
       " 'got_3',\n",
       " '3_baskets',\n",
       " 'baskets_progressing',\n",
       " 'progressing_towards',\n",
       " 'towards_completion',\n",
       " 'completion_fourth',\n",
       " 'fourth_one',\n",
       " 'one_–',\n",
       " '–_difficulties',\n",
       " 'difficulties_areas',\n",
       " 'areas_problems',\n",
       " 'problems_need',\n",
       " 'need_resolved',\n",
       " 'resolved_felt',\n",
       " 'felt_areas',\n",
       " 'areas_there’s',\n",
       " 'there’s_sufficient',\n",
       " 'sufficient_good',\n",
       " 'good_overcome',\n",
       " 'overcome_difficulties',\n",
       " 'difficulties_come',\n",
       " 'come_good',\n",
       " 'good_solution',\n",
       " 'solution_areas',\n",
       " 'areas_commission',\n",
       " 'commission_said',\n",
       " 'said_know',\n",
       " 'know_you’ve',\n",
       " 'you’ve_got',\n",
       " 'got_find',\n",
       " 'find_answers',\n",
       " 'answers_rather',\n",
       " 'rather_unsustainable',\n",
       " 'unsustainable_compromises',\n",
       " 'compromises_sky',\n",
       " 'sky_news',\n",
       " 'news_prime',\n",
       " 'prime_minister',\n",
       " 'minister_start',\n",
       " 'start_8week',\n",
       " '8week_period',\n",
       " 'period_donald',\n",
       " 'donald_tusk',\n",
       " 'tusk_looks',\n",
       " 'looks_sort',\n",
       " 'sort_compromise',\n",
       " 'compromise_meets',\n",
       " 'meets_needs',\n",
       " 'needs_migration',\n",
       " 'migration_guarantee',\n",
       " 'guarantee_whatever',\n",
       " 'whatever_comes',\n",
       " 'comes_actually',\n",
       " 'actually_help',\n",
       " 'help_control',\n",
       " 'control_eu',\n",
       " 'eu_migration',\n",
       " 'migration_lessen',\n",
       " 'lessen_eu',\n",
       " 'eu_migration',\n",
       " 'migration_united',\n",
       " 'united_kingdom',\n",
       " 'kingdom_whole',\n",
       " 'whole_aim',\n",
       " 'aim_stand',\n",
       " 'stand_back',\n",
       " 'back_chosen',\n",
       " 'chosen_4',\n",
       " '4_areas',\n",
       " 'areas_well',\n",
       " 'well_4',\n",
       " '4_things',\n",
       " 'things_think',\n",
       " 'think_concern',\n",
       " 'concern_britain',\n",
       " 'britain_europe',\n",
       " 'europe_people',\n",
       " 'people_concerned',\n",
       " 'concerned_it’s',\n",
       " 'it’s_becoming',\n",
       " 'becoming_single',\n",
       " 'single_currency',\n",
       " 'currency_club',\n",
       " 'club_need',\n",
       " 'need_guarantees',\n",
       " 'guarantees_you’re',\n",
       " 'you’re_outside',\n",
       " 'outside_single',\n",
       " 'single_currency',\n",
       " 'currency_flexibility',\n",
       " 'flexibility_success',\n",
       " 'success_need',\n",
       " 'need_people',\n",
       " 'people_want',\n",
       " 'want_know',\n",
       " 'know_britain',\n",
       " 'britain_particularly',\n",
       " 'particularly_it’s',\n",
       " 'it’s_ever',\n",
       " 'ever_closer',\n",
       " 'closer_union',\n",
       " 'union_we’re',\n",
       " 'we’re_carved',\n",
       " 'carved_people',\n",
       " 'people_want',\n",
       " 'want_know',\n",
       " 'know_adds',\n",
       " 'adds_competitiveness',\n",
       " 'competitiveness_takes',\n",
       " 'takes_away',\n",
       " 'away_competitiveness',\n",
       " 'competitiveness_yes',\n",
       " 'yes_people',\n",
       " 'people_want',\n",
       " 'want_know',\n",
       " 'know_help',\n",
       " 'help_relieve',\n",
       " 'relieve_pressure',\n",
       " 'pressure_terms',\n",
       " 'terms_movement',\n",
       " 'movement_people',\n",
       " 'people_across',\n",
       " 'across_europe',\n",
       " 'europe_britain',\n",
       " 'britain_unwelcoming',\n",
       " 'unwelcoming_we’re',\n",
       " 'we’re_incredibly',\n",
       " 'incredibly_welcoming',\n",
       " 'welcoming_country',\n",
       " 'country_one',\n",
       " 'one_cosmopolitan',\n",
       " 'cosmopolitan_countries',\n",
       " 'countries_earth',\n",
       " 'earth_people',\n",
       " 'people_come',\n",
       " 'come_britain',\n",
       " 'britain_work',\n",
       " 'work_hard',\n",
       " 'hard_make',\n",
       " 'make_life',\n",
       " 'life_strengthens',\n",
       " 'strengthens_country',\n",
       " 'country_british',\n",
       " 'british_people',\n",
       " 'people_totally',\n",
       " 'totally_share',\n",
       " 'share_view',\n",
       " 'view_feel',\n",
       " 'feel_recent',\n",
       " 'recent_years',\n",
       " 'years_pressure',\n",
       " 'pressure_new',\n",
       " 'new_arrivals',\n",
       " 'arrivals_great',\n",
       " 'great_part',\n",
       " 'part_pressure',\n",
       " 'pressure_caused',\n",
       " 'caused_fact',\n",
       " 'fact_generous',\n",
       " 'generous_topup',\n",
       " 'topup_welfare',\n",
       " 'welfare_system',\n",
       " 'system_means',\n",
       " 'means_sometimes',\n",
       " 'sometimes_could',\n",
       " 'could_–',\n",
       " '–_know',\n",
       " 'know_train',\n",
       " 'train_–',\n",
       " '–_nurse',\n",
       " 'nurse_doctor',\n",
       " 'doctor_less',\n",
       " 'less_welloff',\n",
       " 'welloff_european',\n",
       " 'european_countries',\n",
       " 'countries_finished',\n",
       " 'finished_training',\n",
       " 'training_actually',\n",
       " 'actually_pays',\n",
       " 'pays_work',\n",
       " 'work_unskilled',\n",
       " 'unskilled_job',\n",
       " 'job_united',\n",
       " 'united_kingdom',\n",
       " 'kingdom_rather',\n",
       " 'rather_continue',\n",
       " 'continue_nurse',\n",
       " 'nurse_doctor',\n",
       " 'doctor_country',\n",
       " 'country_doesn’t',\n",
       " 'doesn’t_make',\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_eng_bigrams[0][100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we want both unigrams and bigrams in the feature set?\n",
    "assert len(speeches_eng_clean)==len(speeches_eng_bigrams)\n",
    "speeches_eng_uniandbigrams = []\n",
    "for a,b in zip([speech.split() for speech in speeches_eng_clean],speeches_eng_bigrams):\n",
    "    speeches_eng_uniandbigrams.append(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2283, 1141, 1142)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speeches_eng_uniandbigrams[6]),len(speeches_eng_bigrams[6]),len(speeches_eng_clean[6].split())\n",
    "\n",
    "#assert len(speeches_eng_uniandbigrams) == len(speeches_eng_clean)+len(speeches_eng_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"afghanistan\" + 0.001*\"–\" + 0.000*\"afghan\" + 0.000*\"mr_speaker\" + 0.000*\"pakistan\"'),\n",
       " (1,\n",
       "  '0.001*\"–\" + 0.000*\"afghanistan\" + 0.000*\"european\" + 0.000*\"we’re\" + 0.000*\"global\"'),\n",
       " (2,\n",
       "  '0.001*\"–\" + 0.000*\"system\" + 0.000*\"we’re\" + 0.000*\"business\" + 0.000*\"european\"'),\n",
       " (3,\n",
       "  '0.001*\"–\" + 0.000*\"we’re\" + 0.000*\"afghanistan\" + 0.000*\"global\" + 0.000*\"nhs\"'),\n",
       " (4,\n",
       "  '0.001*\"–\" + 0.000*\"israel\" + 0.000*\"mr_speaker\" + 0.000*\"speaker\" + 0.000*\"afghanistan\"'),\n",
       " (5,\n",
       "  '0.001*\"–\" + 0.000*\"european\" + 0.000*\"global\" + 0.000*\"eu\" + 0.000*\"energy\"'),\n",
       " (6,\n",
       "  '0.001*\"–\" + 0.000*\"holocaust\" + 0.000*\"nhs\" + 0.000*\"pakistan\" + 0.000*\"israel\"'),\n",
       " (7,\n",
       "  '0.001*\"–\" + 0.000*\"european\" + 0.000*\"we’re\" + 0.000*\"afghanistan\" + 0.000*\"global\"'),\n",
       " (8,\n",
       "  '0.001*\"–\" + 0.000*\"afghanistan\" + 0.000*\"we’re\" + 0.000*\"global\" + 0.000*\"afghan\"'),\n",
       " (9,\n",
       "  '0.001*\"–\" + 0.000*\"ireland\" + 0.000*\"northern_ireland\" + 0.000*\"northern\" + 0.000*\"legislation\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word_m5 = corpora.Dictionary(speeches_eng_uniandbigrams)                       \n",
    "id2word_m5.filter_extremes(no_below=5, no_above=0.5)\n",
    "ldacorpus_m5 = [id2word_m5.doc2bow(doc) for doc in speeches_eng_uniandbigrams]\n",
    "tfidfcorpus_m5 = models.TfidfModel(ldacorpus_m5)\n",
    "lda_m5 = models.ldamodel.LdaModel(corpus=tfidfcorpus_m5[ldacorpus_m5],id2word=id2word_m5,num_topics=10)\n",
    "lda_m5.print_topics(num_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing up\n",
    "While there are different ways to achieve the desired results and different modules to help you with it (writing from scratch, NLTK, but also gensim.utils), these are some steps to consider when transforming texts to feature sets for topic modeling (recall that not all of them might be neccessary of even diserable, depending on the use case):\n",
    "\n",
    "- transforming to lowercase\n",
    "- removing stopwords\n",
    "- stemming\n",
    "- POS-tagging (and removing unwanted elements)\n",
    "- filtering extremely common and extremely uncommon words\n",
    "- ngrams and/or unigrams as features?\n",
    "- raw frequencies or TF-IDF scores as features?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluating and comparing different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic coherence\n",
    "We can calculate the Umass topic coherence for each topic. See Mimno, Wallach, Talley, Leenders, McCallum: Optimizing Semantic Coherence in Topic Models, CEMNLP 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([(0.00060757634, '–'),\n",
       "   (0.00043317833, 'afghanistan'),\n",
       "   (0.0003880782, 'we’re'),\n",
       "   (0.00030882706, 'global'),\n",
       "   (0.00029865158, 'afghan'),\n",
       "   (0.00028980253, 'european'),\n",
       "   (0.00027704146, 'eu'),\n",
       "   (0.00026334988, 'social'),\n",
       "   (0.00026303672, 'we’ve_got'),\n",
       "   (0.00025426658, 'investment'),\n",
       "   (0.00025373677, 'europe'),\n",
       "   (0.00025318054, 'system'),\n",
       "   (0.00025258903, 'tax'),\n",
       "   (0.00024741955, 'society'),\n",
       "   (0.00024707144, 'president'),\n",
       "   (0.00023866024, 'question'),\n",
       "   (0.0002382211, 'banks'),\n",
       "   (0.00023738366, 'trade'),\n",
       "   (0.00023589125, 'syria'),\n",
       "   (0.00023333226, 'pakistan')],\n",
       "  -0.9908799559816518),\n",
       " ([(0.00070150173, '–'),\n",
       "   (0.00029689164, 'afghanistan'),\n",
       "   (0.0002899771, 'european'),\n",
       "   (0.00028339148, 'we’re'),\n",
       "   (0.00027522107, 'global'),\n",
       "   (0.00027376035, 'wales'),\n",
       "   (0.0002611487, 'president'),\n",
       "   (0.00024619652, 'trade'),\n",
       "   (0.00024397459, 'question'),\n",
       "   (0.00024334068, 'climate'),\n",
       "   (0.00023919699, 'growth'),\n",
       "   (0.00023512958, 'europe'),\n",
       "   (0.00023406855, 'business'),\n",
       "   (0.00023376, 'jobs'),\n",
       "   (0.00023192234, 'g20'),\n",
       "   (0.00022745102, 'g8'),\n",
       "   (0.00022088506, 'libya'),\n",
       "   (0.0002139872, 'syria'),\n",
       "   (0.00021354338, 'actually'),\n",
       "   (0.00021215215, 'oil')],\n",
       "  -0.9969251262992277),\n",
       " ([(0.0006607704, '–'),\n",
       "   (0.0003367581, 'israel'),\n",
       "   (0.00026489838, 'mr_speaker'),\n",
       "   (0.00025608615, 'speaker'),\n",
       "   (0.0002546833, 'afghanistan'),\n",
       "   (0.00024802933, 'trade'),\n",
       "   (0.00024339135, 'global'),\n",
       "   (0.0002424175, 'pakistan'),\n",
       "   (0.00023499377, 'schools'),\n",
       "   (0.00023182435, 'president'),\n",
       "   (0.00022838991, 'climate'),\n",
       "   (0.00022730255, 'peace'),\n",
       "   (0.00022532535, 'secretary'),\n",
       "   (0.00021972792, 'oil'),\n",
       "   (0.00021936247, 'school'),\n",
       "   (0.00021828334, 'mr'),\n",
       "   (0.0002161301, 'banks'),\n",
       "   (0.00021521571, 'climate_change'),\n",
       "   (0.00021478039, 'we’re'),\n",
       "   (0.00021136767, 'system')],\n",
       "  -1.050028912543952),\n",
       " ([(0.0007566265, '–'),\n",
       "   (0.00035228892, 'we’re'),\n",
       "   (0.00035007155, 'afghanistan'),\n",
       "   (0.00034810786, 'global'),\n",
       "   (0.00032457508, 'nhs'),\n",
       "   (0.0003196259, 'pakistan'),\n",
       "   (0.00031934585, 'european'),\n",
       "   (0.00030270574, 'business'),\n",
       "   (0.00029928843, 'trade'),\n",
       "   (0.00029354234, 'question'),\n",
       "   (0.0002911011, 'europe'),\n",
       "   (0.00028694558, 'eu'),\n",
       "   (0.00026281973, 'china'),\n",
       "   (0.00025081675, 'libya'),\n",
       "   (0.00024973534, 'energy'),\n",
       "   (0.00024119641, 'businesses'),\n",
       "   (0.00023605835, 'deficit'),\n",
       "   (0.00023540958, 'afghan'),\n",
       "   (0.0002331573, 'child'),\n",
       "   (0.00023262262, 'nuclear')],\n",
       "  -1.158715273110876),\n",
       " ([(0.0005486689, '–'),\n",
       "   (0.0002668619, 'european'),\n",
       "   (0.00026387957, 'we’re'),\n",
       "   (0.0002576398, 'afghanistan'),\n",
       "   (0.00025704343, 'global'),\n",
       "   (0.0002346289, 'president'),\n",
       "   (0.00023323814, 'g20'),\n",
       "   (0.00021570605, 'banks'),\n",
       "   (0.00021154566, 'agreed'),\n",
       "   (0.00020790222, 'iran'),\n",
       "   (0.00020785841, 'business'),\n",
       "   (0.00020546027, 'rights'),\n",
       "   (0.00020179962, 'nuclear'),\n",
       "   (0.00020090872, 'europe'),\n",
       "   (0.00020025876, 'trade'),\n",
       "   (0.00019052789, 'growth'),\n",
       "   (0.00018739878, 'financial'),\n",
       "   (0.00018716473, 'romania'),\n",
       "   (0.00018148607, 'eurozone'),\n",
       "   (0.0001810132, 'infrastructure')],\n",
       "  -1.3534667398403184),\n",
       " ([(0.0005801537, '–'),\n",
       "   (0.00038059737, 'ireland'),\n",
       "   (0.00035947093, 'northern_ireland'),\n",
       "   (0.00034070128, 'northern'),\n",
       "   (0.00026957487, 'legislation'),\n",
       "   (0.0002606486, 'european'),\n",
       "   (0.0002598972, 'we’re'),\n",
       "   (0.00024840355, 'eu'),\n",
       "   (0.00024225362, 'afghanistan'),\n",
       "   (0.00023100815, 'wales'),\n",
       "   (0.00022509354, 'local'),\n",
       "   (0.00022311723, 'forces'),\n",
       "   (0.00022199776, 'europe'),\n",
       "   (0.00022114982, 'afghan'),\n",
       "   (0.00021736925, 'tourism'),\n",
       "   (0.00021731657, 'question'),\n",
       "   (0.00021716865, 'bill'),\n",
       "   (0.00021680091, 'mr_speaker'),\n",
       "   (0.00021338127, 'faith'),\n",
       "   (0.00020500513, 'public')],\n",
       "  -1.49086043251631),\n",
       " ([(0.0005189201, '–'),\n",
       "   (0.00027072307, 'system'),\n",
       "   (0.0002605044, 'we’re'),\n",
       "   (0.000248639, 'business'),\n",
       "   (0.00022940552, 'european'),\n",
       "   (0.0002228488, 'banks'),\n",
       "   (0.0002214981, 'indistinct'),\n",
       "   (0.00022100897, 'nuclear'),\n",
       "   (0.00021839987, 'businesses'),\n",
       "   (0.0002143482, 'question'),\n",
       "   (0.00021141797, 'iran'),\n",
       "   (0.00020876559, 'nhs'),\n",
       "   (0.00020860933, 'isil'),\n",
       "   (0.00020833849, 'global'),\n",
       "   (0.00019627932, 'health'),\n",
       "   (0.00019494601, 'service'),\n",
       "   (0.00019253886, 'young'),\n",
       "   (0.00019115927, 'money'),\n",
       "   (0.0001909984, 'communities'),\n",
       "   (0.00019074426, 'lending')],\n",
       "  -1.4951258814338457),\n",
       " ([(0.00050722307, 'afghanistan'),\n",
       "   (0.0005042764, '–'),\n",
       "   (0.00043786896, 'afghan'),\n",
       "   (0.00040396163, 'mr_speaker'),\n",
       "   (0.00040069717, 'pakistan'),\n",
       "   (0.00034859433, 'speaker'),\n",
       "   (0.00032450224, 'bill'),\n",
       "   (0.00027373098, 'mr'),\n",
       "   (0.00026959524, 'forces'),\n",
       "   (0.00025504283, 'global'),\n",
       "   (0.00023210136, 'we’re'),\n",
       "   (0.00023016591, 'agreed'),\n",
       "   (0.00022277757, 'president'),\n",
       "   (0.00021688784, 'police'),\n",
       "   (0.000215739, 'european'),\n",
       "   (0.00021266786, 'system'),\n",
       "   (0.00020517374, 'army'),\n",
       "   (0.00020428745, 'trade'),\n",
       "   (0.00020322631, 'taleban'),\n",
       "   (0.00020086624, 'palestinian')],\n",
       "  -1.5023578721948219),\n",
       " ([(0.0005506396, '–'),\n",
       "   (0.00031491893, 'european'),\n",
       "   (0.00029537076, 'global'),\n",
       "   (0.00026833813, 'eu'),\n",
       "   (0.0002626316, 'energy'),\n",
       "   (0.0002595279, 'nhs'),\n",
       "   (0.00025820552, 'iraq'),\n",
       "   (0.00024850765, 'afghanistan'),\n",
       "   (0.000246586, 'nuclear'),\n",
       "   (0.0002420683, 'carbon'),\n",
       "   (0.00023074952, 'care'),\n",
       "   (0.00022359767, 'we’re'),\n",
       "   (0.00021955157, 'climate_change'),\n",
       "   (0.00021946264, 'question'),\n",
       "   (0.0002191287, 'banks'),\n",
       "   (0.00021727991, 'cooper'),\n",
       "   (0.00021322642, 'eurozone'),\n",
       "   (0.00021305033, 'climate'),\n",
       "   (0.0002116488, 'social'),\n",
       "   (0.00021075476, 'trade')],\n",
       "  -1.7325106424258436),\n",
       " ([(0.0005914679, '–'),\n",
       "   (0.00030463978, 'holocaust'),\n",
       "   (0.00023981305, 'nhs'),\n",
       "   (0.00023139852, 'pakistan'),\n",
       "   (0.00022367985, 'israel'),\n",
       "   (0.00022006156, 'police'),\n",
       "   (0.00021825096, 'immigration'),\n",
       "   (0.00020915597, 'palestinian'),\n",
       "   (0.00020786953, 'we’re'),\n",
       "   (0.00019566821, 'gordon'),\n",
       "   (0.0001951324, 'afghanistan'),\n",
       "   (0.00019508597, 'brown'),\n",
       "   (0.000194139, 'war'),\n",
       "   (0.00019361985, 'tonight'),\n",
       "   (0.00018403248, 'russia'),\n",
       "   (0.00018278806, 'health'),\n",
       "   (0.00018155048, 'gordon_brown'),\n",
       "   (0.00018115721, 'we’ve_got'),\n",
       "   (0.00018045674, 'health_service'),\n",
       "   (0.00017925414, 'aid')],\n",
       "  -1.904655707755291)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print coherence per topic:\n",
    "lda_m5.top_topics(ldacorpus_m5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence of naive model = -0.03546400993305011\n",
      "Coherence of clean model = -0.2094496545063948\n",
      "Coherence of tf-idf model = -1.035845034477871\n",
      "Coherence of tf-idf model without extreme words -1.231415715388437\n",
      "NB: Note that it may not make too much sense to compare these vaues across different corpora\n"
     ]
    }
   ],
   "source": [
    "# Or: overall coherence\n",
    "# NB: CoherenceModel is only available in newer versions of gensim.\n",
    "# if it's not available, consider upgrading with `pip3 install gensim -upgrade`\n",
    "cm1 = models.CoherenceModel(model=lda_m1, corpus=ldacorpus_m1, dictionary= id2word_m1, coherence='u_mass')  \n",
    "naivecoh = cm1.get_coherence()\n",
    "cm2 = models.CoherenceModel(model=lda_m2, corpus=ldacorpus_m2, dictionary= id2word_m2, coherence='u_mass')  \n",
    "cleancoh = cm2.get_coherence()\n",
    "#cm3 = models.CoherenceModel(model=lda_m3, corpus=ldacorpus_m3, coherence='u_mass')\n",
    "cm3 = models.CoherenceModel(model=lda_m3, corpus=tfidfcorpus_m3[ldacorpus_m3], dictionary= id2word_m3, coherence='u_mass')\n",
    "tfidfcoh = cm3.get_coherence()\n",
    "cm4 = models.CoherenceModel(model=lda_m4, corpus=tfidfcorpus_m4[ldacorpus_m4], dictionary= id2word_m4, coherence='u_mass')\n",
    "tfidffiltercoh = cm4.get_coherence()\n",
    "print(\"Coherence of naive model = {}\\nCoherence of clean model = {}\\nCoherence of tf-idf model = {}\\nCoherence of tf-idf model without extreme words {}\".format(naivecoh, cleancoh, tfidfcoh,tfidffiltercoh))\n",
    "print(\"NB: Note that it may not make too much sense to compare these vaues across different corpora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8559407020909235\n",
      "-10.82568706183331\n"
     ]
    }
   ],
   "source": [
    "lda_m4_bad = models.LdaModel(tfidfcorpus_m4[ldacorpus_m4], id2word=id2word_m4, num_topics=10,iterations=1)\n",
    "print(models.CoherenceModel(model=lda_m4_bad, corpus=tfidfcorpus_m4[ldacorpus_m4], coherence='u_mass').get_coherence())\n",
    "\n",
    "lda_m4_good = models.LdaModel(tfidfcorpus_m4[ldacorpus_m4], id2word=id2word_m4, num_topics=10,iterations=50, passes=5)\n",
    "print(models.CoherenceModel(model=lda_m4_good, corpus=tfidfcorpus_m4[ldacorpus_m4], coherence='u_mass').get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_m4_bad.top_topics(tfidfcorpus_m4[ldacorpus_m4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_m4_good.top_topics(tfidfcorpus_m4[ldacorpus_m4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_m3.top_topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= cm1.get_coherence_per_topic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Visualizing and interactively exploring topic models\n",
    "A great tool for interactively exploring topicmodels is pyLDAvis.\n",
    "pyLDAvis can estimate its own topic models, but it als has a nice function called `gensim.prepare`, which you can use to visualize the model you already estimated with gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = gensimvis.prepare(lda_m5,ldacorpus_m5,id2word_m5)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. What’s the next step in the pipeline? Using the results of a topic model\n",
    "\n",
    "Until know, we have mainly considered the interpretation of the topics themselves. While it can indeed be interesting to use topic models to summarize and interpret large corpora, this is usually not where social scientists stop: We want to relate the topics back to documents to say something about which topics occur in which documents.\n",
    "\n",
    "## Saving topic scores to a file\n",
    "Somewhat similar to factor analysis and principal component analysis, where one can also store factor scores that indicate how high a specific case scores on each of the factors that were identified, for each document, we can estimate a score for each of the topics we identified.\n",
    "\n",
    "To do so, we can simply call the `.inference()` method on the model we estimated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresperdoc=lda_m5.inference(ldacorpus_m5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scoresperdoc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do a lot of different stuff with the resulting matrix, in which each row represents one of the documents and each row consists of one score for each topic.\n",
    "For example, we just could create a tab-separated file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"topicscores.tsv\",\"w\",encoding=\"utf-8\") as fo:\n",
    "    for row in scoresperdoc[0]:\n",
    "       fo.write(\"\\t\".join([\"{:0.3f}\".format(score) for score in row]))\n",
    "       fo.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or we put it into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(scoresperdoc[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that these scores are extremely skewed. Maybe we just want to know which topics score really high? Let's recode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df.applymap(lambda x: int(x>10))\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a heatmap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 20))\n",
    "sns.heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning alpha and eta\n",
    "different parameters. From docstring:\n",
    "```\n",
    "`alpha` and `eta` are hyperparameters that affect sparsity of the document-topic\n",
    "(theta) and topic-word (lambda) distributions. Both default to a symmetric\n",
    "1.0/num_topics prior.\n",
    "\n",
    "`alpha` can be set to an explicit array = prior of your choice. It also\n",
    "support special values of 'asymmetric' and 'auto': the former uses a fixed\n",
    "normalized asymmetric 1.0/topicno prior, the latter learns an asymmetric\n",
    "prior directly from your data.\n",
    "\n",
    "`eta` can be a scalar for a symmetric prior over topic/word\n",
    "distributions, or a matrix of shape num_topics x num_words, which can\n",
    "be used to impose asymmetric priors over the word distribution on a\n",
    "per-topic basis. This may be useful if you want to seed certain topics\n",
    "with particular words by boosting the priors for those words.  It also\n",
    "supports the special value 'auto', which learns an asymmetric prior\n",
    "directly from your data.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# example for different specification: repeat analysis 10 times, while learning alpha and eta from the data \n",
    "# instead of using 1/number of topics as defailt\n",
    "lda_m6 = models.ldamodel.LdaModel(corpus=tfidfcorpus_m5[ldacorpus_m5],id2word=id2word_m5,num_topics=50, alpha='auto', eta = 'auto',passes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with this specific data, this fails b/c of a fitting issue (there is a complex number instead of a float returned somewhere)\n",
    "vis_data = gensimvis.prepare(lda_m6,ldacorpus_m5,id2word_m5)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Plotting over time\n",
    "\n",
    "Please find here another example that illustrates how to plot topic scores over time, as one example for follow-up analysis.\n",
    "\n",
    "\n",
    "The `.inference()` method used on the slides and above under chapter 7 gives raw gamma scores (between zero and +infinity). That’s a bit hard to interpret in a plot, so here we will use `.get_document_topics` instead. That will return normalized scores. You can achieve the same result by normalizing the output of `.inference()` yourself (e.g., `normalizedtopicscores = (originalscores.T/originalscores.sum(axis=1)).T`)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob('speeches_UK_Cleaned.csv')\n",
    "print(filelist)\n",
    "dates = []\n",
    "speeches_eng=[]\n",
    "for fn in filelist:\n",
    "    with open(fn) as fi:\n",
    "        reader=csv.reader(fi)\n",
    "        for row in reader:\n",
    "            if row[7]=='en':   # only include english-language speches; we might as well choose 'nl' or 'fr'\n",
    "                speeches_eng.append(row[5])\n",
    "                dates.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches=[speech.replace('<p>',' ').replace('</p>',' ') for speech in speeches_eng]   #remove HTML tags\n",
    "speeches=[\"\".join([l for l in speech if l not in punctuation]) for speech in speeches]  #remove punctuation\n",
    "speeches=[speech.lower() for speech in speeches]  # convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldainput_m10 = [speech.split() for speech in speeches]           \n",
    "id2word_m10 = corpora.Dictionary(ldainput_m10)                       \n",
    "\n",
    "id2word_m10.filter_extremes(no_below=5, no_above=0.5)   # do not consider all words that occur in less than n=5 documents\n",
    "                                                    # or in more than 50% of all documents.\n",
    "\n",
    "ldacorpus_m10 = [id2word_m10.doc2bow(doc) for doc in ldainput_m10]\n",
    "tfidfcorpus_m10 = models.TfidfModel(ldacorpus_m10)\n",
    "lda_m10 = models.ldamodel.LdaModel(corpus=tfidfcorpus_m10[ldacorpus_m10],id2word=id2word_m10,num_topics=10, passes=5, alpha='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert your topics back to a df\n",
    "all_topics = lda_m10.get_document_topics(ldacorpus_m10, minimum_probability=0.0)\n",
    "all_topics_csr = gensim.matutils.corpus2csc(all_topics)\n",
    "all_topics_numpy = all_topics_csr.T.toarray()\n",
    "all_topics_df = pd.DataFrame(all_topics_numpy)\n",
    "\n",
    "all_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each value in a row by the sum of the row to normalize the values\n",
    "all_topics_df.rename(columns= { 0 : \"topic_0\", 1 : \"topic_1\", 2 : \"topic_2\", 3 : \"topic_3\",\n",
    "4 : \"topic_4\", 5 : \"topic_5\", 6 : \"topic_6\", 7 : \"topic_7\", 8 : \"topic_8\", 9 : \"topic_9\" },inplace=True)\n",
    "all_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a df with the dates and orginal texts\n",
    "\n",
    "meta = pd.DataFrame(zip(dates, speeches_eng))\n",
    "meta.rename(columns = {0: \"date\", 1 : \"speeches\"}, inplace=True)\n",
    "\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge with the topic scores per document\n",
    "\n",
    "final = pd.concat([meta, all_topics_df], axis=1)\n",
    "final['id'] = final.index\n",
    "final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reshape to long format\n",
    "\n",
    "long = pd.melt(final, id_vars=['id', 'date', 'speeches'], value_vars=[f\"topic_{i}\" for i in range(0,10)])\n",
    "long.rename(columns={\"variable\" : \"topic_nr\", \"value\" : \"topic_score\"}, inplace=True)\n",
    "long.head(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data in right shape for plotting\n",
    "\n",
    "long['date'] = long['date'].map(pd.to_datetime)\n",
    "plotdf = long.groupby(['topic_nr',pd.Grouper(key='date', freq='Y')]).mean().reset_index()\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "sns.lineplot(x=\"date\", y=\"topic_score\", hue=\"topic_nr\", data=plotdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINISHED RUNNING:\",str(datetime.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
