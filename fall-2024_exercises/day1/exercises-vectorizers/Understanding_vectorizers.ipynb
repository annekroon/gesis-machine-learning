{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3903bc69",
   "metadata": {},
   "source": [
    "# Understanding vectorizers\n",
    "\n",
    "In the following code examples, we will experiment with vectorizers to understand a bit better how they work. Feel free to adjust the code, and try things out yourself.\n",
    "\n",
    "For now, we will practice with `sklearn`'s vectorizers. however, packages such as `gensim` offer their own build in functionality to vectorize the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6288fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbfbd6",
   "metadata": {},
   "source": [
    "## Example 1: Inspect the output of a vectorizer in a dense format\n",
    "\n",
    "The following code cell will fit and transform three documents using a `Count`-based vectorizer. Next, the output is transformed to a *dense* matrix, and printed. \n",
    "\n",
    "1. Do you understand the output?\n",
    "2. Is it smart to transform output to a dense format? What will happen if you work with millions of documents, rather than 3 short sentences?\n",
    "3. what happens if you replace `CountVectorizer()` for `TfidfVectorizer()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49495cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"hello students!\", \"how are you today?\", \"what?\", \"hello hello everybody\"]\n",
    "vect = CountVectorizer()# initialize the vectorizer\n",
    "\n",
    "X = vect.fit_transform(texts) #fit the vectorizer and transform the documents in one go\n",
    "print(pd.DataFrame(X.A, columns=vect.get_feature_names_out()).to_string())\n",
    "df = pd.DataFrame(X.toarray().transpose(), index = vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8d55e",
   "metadata": {},
   "source": [
    "## Example 2: Inspect the output of a vectorizer in a sparse format\n",
    "\n",
    "Internally, `sklearn` represents the data in a *sparse* format, as this is computationally more efficient, and less memory is required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bfaeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"hello students!\", \"how are you today?\", \"what?\", \"hello hello everybody\"]\n",
    "count_vec = CountVectorizer() #initilize the vectorizer\n",
    "count_vec_fit = count_vec.fit_transform(texts) #fit the vectorizer and transform the documents in one go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95a380b",
   "metadata": {},
   "source": [
    "    1.Inspect the shape of transformed texts. We can see that we have a 4x8 sparse matrix, meaning that we have 4 \n",
    "    rows (=documents) and 8 unique tokens (=words, numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9363fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e134c2",
   "metadata": {},
   "source": [
    "    2.Get the feature names. This will return the tokens that are in the vocabulary of the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c92ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c6b9a0",
   "metadata": {},
   "source": [
    "    3. Represent the token's mapping to it's id values. The numbers do *not* represent the count of the words but the position of the words in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf16fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec.vocabulary_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f3fb63",
   "metadata": {},
   "source": [
    "    4. Get sparse representation on document level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, document in zip(count_vec_fit, texts):\n",
    "    print(document)\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52645b99",
   "metadata": {},
   "source": [
    "a. Do you understand the output printed above?  \n",
    "b. What happens if you change the `count` to a `tfidf` vectorizer?  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
