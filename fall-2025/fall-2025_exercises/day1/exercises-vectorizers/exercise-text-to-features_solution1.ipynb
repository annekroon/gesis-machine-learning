{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Working with textual data\n",
    "\n",
    "### 0. Get the data.\n",
    "\n",
    "- Download the dataset from https://surfdrive.surf.nl/files/index.php/s/bfNFkuUVoVtiyuk. This is a subset of the data from https://doi.org/10.7910/DVN/YHWTFC. \n",
    "\n",
    "- Unpack it. On Linux and MacOS, you can do this with `tar -xzf mydata.tar.gz` on the command line. On Windows, you may need an additional tool such as `7zip` for that (note that technically speaking, there is a `tar` archive within a `gz` archive, so unpacking may take *two* steps depending on your tool).\n",
    "\n",
    "\n",
    "### 1. Inspect the structure of the dataset.\n",
    "What information do the following elements give you?\n",
    "\n",
    "- folder (directory) names\n",
    "- folder structure/hierarchy\n",
    "- file names\n",
    "- file contents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Discuss strategies for working with this dataset!\n",
    "\n",
    "- Which questions could you answer?\n",
    "- How could you deal with it, given the size and the structure?\n",
    "- How much memory<sup>1</sup> (RAM) does your computer have? How large is the complete dataset? What does that mean?\n",
    "- Make a sketch (e.g., with pen&paper), how you could handle your workflow and your data to answer your question.\n",
    "\n",
    "<sup>1</sup> *memory* (RAM), not *storage* (harddisk)!\n",
    "\n",
    "### 3. Read some (or all?) data\n",
    "\n",
    "Here is some example code that you can modify. Assuming that the folder `articles` is in the same folder as the notebook you are currently working on, you could, for instance, do the following to read a *part* of your dataset.\n",
    "\n",
    "```python\n",
    "from glob import glob\n",
    "infowarsfiles = glob('articles/*/Infowars/*')\n",
    "infowarsarticles = []\n",
    "for filename in infowarsfiles:\n",
    "    with open(filename) as f:\n",
    "\t    infowarsarticles.append(f.read())\n",
    "\n",
    "```\n",
    "\n",
    "- Can you explain what the `glob` function does?\n",
    "- What does `infowarsfiles` contain, and what does `infowarsarticles` contain? First make an educated guess based on the code snippet, then check it! Do *not* print the whole thing, but use `len`, `type` en slicing `[:10]` to get the info you need.\n",
    "\n",
    "- Tip: take a random sample of the articles for practice purposes (if your code works, you can scale up!)\n",
    "\n",
    "```\n",
    "# taking a random sample of the articles for practice purposes\n",
    "articles =random.sample(infowarsarticles, 10)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os  \n",
    "import random\n",
    "import nltk \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data_dir = r\"C:/Data Management/Gesis IML/articles-small\" #adjust this to your data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infowarsfiles = glob(os.path.join(data_dir, 'articles/*/Infowars/*'))\n",
    "infowarsarticles = []\n",
    "for filename in infowarsfiles:\n",
    "    with open(filename) as f:\n",
    "\t    infowarsarticles.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a random sample of the articles for practice purposes\n",
    "articles = random.sample(infowarsarticles, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Vectorize the data\n",
    "\n",
    "Imagine you want to train a classifier that will predict whether articles come from a fake news source (e.g., `Infowars`) or a quality news outlet (e.g., `bbc`). In other words, you want to predict `source` based on linguistic variations in the articles.\n",
    "\n",
    "To arrive at a model that will do just that, you have to transform 'text' to 'features'.\n",
    "\n",
    "- Can you vectorize the data? Try defining different vectorizers. Consider the following options:\n",
    "    - `count` vs. `tfidf` vectorizers\n",
    "    - with/ without pruning\n",
    "    - with/ without stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A high school in Vermonts capital raised a Black Lives Matter flag Thursday morning in honor of Black History Month.\\n\\nStudents at Montpelier High School, where 18 of 350 students are black, took turns raising the flag in a ceremony attended by hundreds of students, staff and community members.\\n\\nThe decision to fly the flag had drawn criticism from Republican state legislator Thomas Terenzini, who told WPTZ this week that the school was setting a bad example.',\n",
       " 'A Monmouth Poll released on Wednesday that shows the heavily hyped Democratic generic Congressional ballot advantage has virtually disappeared is the latest poll indicating Democratic chances for major Congressional midterm gains are trending down.\\n\\nOn December 22, the Real Clear Politics Average of Polls gave Democrats a 13-point advantage in the generic Congressional ballot.\\n\\nBreitbart News reported last month  when the January 19 Real Clear Politics Average of Polls gave Democrats a 7.8-point advantage in the generic Congressional ballot  the heavily hyped 2018 Blue Wave on which the 77-year-olds dream of Democratic Party restoration rests may have already reached its crest.\\n\\nThe Real Clear Politics Average of Polls as of February 1 still shows Democrats have a 7.3 percent generic Congressional ballot advantage, but the more recent polls included in that average show the advantage to be much lower.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infowarsarticles[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'to', 'of', 'and', 'in', 'that', 'is', 'on', 'for', 'was', 'with', 'trump', 'as', 'he', 'it', 'by', 'are', 'at', 'this', 'have', 'said', 'be', 'his', 'not', 'an', 'has', 'they', 'who', 'from', 'president', 'you', 'we', 'about', 'their', 'were', 'people', 'but', 'or', 'its', 'out', 'will', 'after', 'which', 'one', 'would', 'been', 'all', 'she', 'if', 'her']\n"
     ]
    }
   ],
   "source": [
    "cnt_vectorizer = CountVectorizer()\n",
    "cnt_vectorizer.fit(infowarsarticles)\n",
    "#find the most frequent words\n",
    "mystopwords = cnt_vectorizer.get_feature_names_out()[cnt_vectorizer.transform(infowarsarticles).sum(axis=0).A1.argsort()[::-1][:50]].tolist()\n",
    "print(mystopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vectorizer_stop = CountVectorizer(stop_words=mystopwords)\n",
    "cnt_vectorizer_stop75_2 = CountVectorizer(stop_words=mystopwords, max_df=.75, min_df=2)\n",
    "cnt_vectorizer_stop75_2_tree = CountVectorizer(tokenizer=nltk.TreebankWordTokenizer().tokenize, stop_words=mystopwords, max_df=.75, min_df=2,\n",
    "    token_pattern=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Fit a classifier\n",
    "\n",
    "- Try out a simple supervised model. Find some inspiration [here](possible-solution-exercise-day1.md). Can you predict the `source` using linguistic variations in the articles?\n",
    "\n",
    "- Which combination of pre-processing steps + vectorizer gives the best results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(listofoutlets):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for label in listofoutlets:\n",
    "        for file in glob(os.path.join(data_dir, 'articles', '*', label, '*')):\n",
    "            with open(file) as f:\n",
    "                texts.append(f.read())\n",
    "                labels.append(label)\n",
    "    return texts, labels\n",
    "\n",
    "X, y = read_data(['Infowars', 'The Guardian']) #choose your own newsoutlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy count: 0.835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Infowars       0.94      0.72      0.82       414\n",
      "The Guardian       0.76      0.95      0.85       386\n",
      "\n",
      "    accuracy                           0.83       800\n",
      "   macro avg       0.85      0.84      0.83       800\n",
      "weighted avg       0.86      0.83      0.83       800\n",
      "\n",
      "Accuracy count_stop: 0.8275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Infowars       0.93      0.72      0.81       414\n",
      "The Guardian       0.76      0.94      0.84       386\n",
      "\n",
      "    accuracy                           0.83       800\n",
      "   macro avg       0.84      0.83      0.83       800\n",
      "weighted avg       0.85      0.83      0.83       800\n",
      "\n",
      "Accuracy count_pruned: 0.8425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Infowars       0.90      0.79      0.84       414\n",
      "The Guardian       0.80      0.90      0.85       386\n",
      "\n",
      "    accuracy                           0.84       800\n",
      "   macro avg       0.85      0.84      0.84       800\n",
      "weighted avg       0.85      0.84      0.84       800\n",
      "\n",
      "Accuracy count_treebank: 0.8525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Infowars       0.96      0.74      0.84       414\n",
      "The Guardian       0.78      0.97      0.86       386\n",
      "\n",
      "    accuracy                           0.85       800\n",
      "   macro avg       0.87      0.86      0.85       800\n",
      "weighted avg       0.87      0.85      0.85       800\n",
      "\n",
      "Accuracy tfidf: 0.7975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Infowars       0.94      0.65      0.77       414\n",
      "The Guardian       0.72      0.96      0.82       386\n",
      "\n",
      "    accuracy                           0.80       800\n",
      "   macro avg       0.83      0.80      0.79       800\n",
      "weighted avg       0.83      0.80      0.79       800\n",
      "\n",
      "Accuracy tfidf_bigrams: 0.72625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Infowars       0.99      0.48      0.64       414\n",
      "The Guardian       0.64      0.99      0.78       386\n",
      "\n",
      "    accuracy                           0.73       800\n",
      "   macro avg       0.81      0.74      0.71       800\n",
      "weighted avg       0.82      0.73      0.71       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compare performance of different vectorizers:\n",
    "\n",
    "vectorizers = { \"count\": CountVectorizer(), \n",
    "               \"count_stop\": CountVectorizer(stop_words=mystopwords), \n",
    "               \"count_pruned\": CountVectorizer(stop_words=mystopwords, max_df=0.6, min_df=5), \n",
    "               \"count_treebank\": CountVectorizer(tokenizer=nltk.TreebankWordTokenizer().tokenize, token_pattern=None), \n",
    "               \"tfidf\": TfidfVectorizer(max_df=0.6, min_df=5), \n",
    "               \"tfidf_bigrams\": TfidfVectorizer(ngram_range=(1,2), max_df=0.6, min_df=5) }\n",
    "\n",
    "for vectorizer_name, vectorizer in vectorizers.items():\n",
    "    model = MultinomialNB()\n",
    "    X_features_train = vectorizer.fit_transform(X_train)\n",
    "    X_features_test = vectorizer.transform(X_test)\n",
    "    model.fit(X_features_train, y_train)\n",
    "    y_pred = model.predict(X_features_test)\n",
    "\n",
    "    print(f\"Accuracy {vectorizer_name}: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: Inceasing efficiency + reusability\n",
    "The approach under (3) gets you very far.\n",
    "But for those of you who want to go the extra mile, here are some suggestions for further improvements in handling such a large dataset, consisting of thousands of files, and for deeper thinking about data handling:\n",
    "\n",
    "- Consider writing a function to read the data. Let your function take three parameters as input, `basepath` (where is the folder with articles located?), `month` and `outlet`, and return the articles that match this criterion.\n",
    "- Even better, make it a *generator* that yields the articles instead of returning a whole list.\n",
    "- Consider yielding a dict (with date, outlet, and the article itself) instead of yielding only the article text.\n",
    "- Think of the most memory-efficient way to get an overview of how often a given regular expression R is mentioned per outlet!\n",
    "- Under which circumstances would you consider having your function for reading the data return a pandas dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gesis_iml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
