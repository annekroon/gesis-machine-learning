
@article{Boumans2016,
author = {Boumans, Jelle W. and Trilling, Damian},
doi = {10.1080/21670811.2015.1096598},
file = {:Users/damian/Dropbox/uva/literatuur-mendeley/Boumans, Trilling{\_}2016.pdf:pdf},
issn = {2167-0811},
journal = {Digital Journalism},
number = {1},
pages = {8--23},
title = {Taking stock of the toolkit: An overview of relevant autmated content analysis approaches and techniques for digital journalism scholars},
volume = {4},
year = {2016}
}



@misc{Pennebaker2007,
	address = {Austin; TX},
	author = {Pennebaker, J. W. and Booth, R. J. and Francis, M. E.},
	publisher = {LIWC.net},
	title = {{Linguistic Inquiry and Word Count: LIWC}},
	year = {2007}
}




@inproceedings{Hutto2014,
	title={Vader: A parsimonious rule-based model for sentiment analysis of social media text},
	author={Hutto, Clayton J and Gilbert, Eric},
	booktitle={Eighth International AAAI Conference on Weblogs and Social Media},
	year={2014}
}




@article{Boukes2020,
	author = {Boukes, Mark and van de Velde, Bob and Araujo, Theo and Vliegenthart, Rens},
	doi = {10.1080/19312458.2019.1671966},
	issn = {1931-2458},
	journal = {Communication Methods and Measures},
	number = {2},
	pages = {83--104},
	publisher = {Routledge},
	title = {{What's the Tone? Easy Doesn't Do It: Analyzing Performance and Agreement Between Off-the-Shelf Sentiment Analysis Tools}},
	volume = {14},
	year = {2020}
}




@article{VanAtteveldt2021,
	author = {{van Atteveldt}, Wouter and {van der Velden}, Mariken A.C.G. and Boukes, Mark},
	doi = {10.1080/19312458.2020.1869198},
	issn = {19312466},
	journal = {Communication Methods and Measures},
	number = {00},
	pages = {1--20},
	publisher = {Routledge},
	title = {{The Validity of Sentiment Analysis:Comparing Manual Annotation, Crowd-Coding, Dictionary Approaches, and Machine Learning Algorithms}},
	volume = {00},
	year = {2021}
}



@article{Vermeer2019,
	author = {Vermeer, Susan and Araujo, Theo and Bernritter, Stefan F. and van Noort, Guda},
	doi = {10.1016/j.ijresmar.2019.01.010},
	issn = {01678116},
	journal = {International Journal of Research in Marketing},
	number = {3},
	pages = {492--508},
	publisher = {Elsevier B.V.},
	title = {{Seeing the wood for the trees: How machine learning can help firms in identifying relevant electronic word-of-mouth in social media}},
	volume = {36},
	year = {2019}
}



@article{Burscher2015,
	author = {Burscher, Bj{\"{o}}rn and Vliegenthart, Rens and {De Vreese}, C. H.},
	doi = {10.1177/0002716215569441},
	issn = {0002-7162},
	journal = {The ANNALS of the American Academy of Political and Social Science},
	number = {1},
	pages = {122--131},
	title = {{Using supervised machine learning to code policy issues: Can classifiers generalize across contexts?}},
	volume = {659},
	year = {2015}
}




@article{Burscher2014,
	author = {Burscher, Bj{\"{o}}rn and Odijk, Daan and Vliegenthart, Rens and de Rijke, Maarten and de Vreese, Claes H.},
	doi = {10.1080/19312458.2014.937527},
	issn = {1931-2458},
	journal = {Communication Methods and Measures},
	number = {3},
	pages = {190--206},
	title = {Teaching the computer to code frames in news: {C}omparing two supervised machine learning approaches to frame analysis},
	volume = {8},
	year = {2014}
}


@article{Hopkins2010,
	author = {Hopkins, Daniel J. and King, Gary},
	journal = {American Journal of Political Science},
	number = {1},
	pages = {229--247},
	title = {{A method of automated nonparametric content analysis for social science}},
	volume = {54},
	year = {2010}
}


@inproceedings{BERT,
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5{\%} (7.7{\%} point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	archivePrefix = {arXiv},
	arxivId = {1810.04805},
	author = {Devlin, Jacob and Chang, Ming Wei and Lee, Kenton and Toutanova, Kristina},
	booktitle = {NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - Proceedings of the Conference},
	eprint = {1810.04805},
	file = {:home/damian/SURFdrive/literatuur-mendeley/Devlin et al.{\_}2019.pdf:pdf},
	isbn = {9781950737130},
	number = {Mlm},
	pages = {4171--4186},
	title = {{BERT: Pre-training of deep bidirectional transformers for language understanding}},
	volume = {1},
	year = {2019}
}
